# Server Configuration
server:
  host: "0.0.0.0"
  port: 8000
  debug: false
  cors_origins: ["*"]

# TTS Backend Configuration
tts:
  # Primary backend (fastest, always available)
  primary_backend: "edge"
  
  # Fallback backends in order of preference
  fallback_backends: ["piper", "xtts"]
  
  # Backend-specific settings
  backends:
    edge:
      enabled: true
      default_voice: "zh-CN-XiaoxiaoNeural"
      rate: "+0%"
      volume: "+0%"
    
    piper:
      enabled: true
      model_path: "./models/piper"
      default_voice: "zh_CN-huayan-medium"
      
    xtts:
      enabled: true
      model_path: "./models/xtts"
      device: "cuda"  # Use GPU acceleration
      max_batch_size: 4
      enable_deepspeed: false
      
    azure:
      enabled: false
      subscription_key: ""
      region: ""
      
    openai:
      enabled: false
      api_key: ""
      model: "tts-1"

# Audio Settings
audio:
  sample_rate: 22050
  format: "wav"
  quality: "medium"  # low, medium, high
  normalize: true
  
# Performance Settings
performance:
  # GPU settings
  gpu:
    enabled: true
    device: "cuda:0"
    memory_fraction: 0.6  # Use 60% of GPU memory
    
  # Caching
  cache:
    enabled: true
    type: "memory"  # memory, redis, file
    max_size_mb: 500
    ttl_seconds: 3600
    
  # Queue management
  queue:
    max_concurrent: 10
    timeout_seconds: 30
    priority_enabled: true

# Live Streaming Settings
streaming:
  buffer_size: 4096
  chunk_duration_ms: 100
  websocket_timeout: 60
  
# Logging
logging:
  level: "INFO"
  file: "logs/tts_server.log"
  rotation: "1 day"
  retention: "7 days"
